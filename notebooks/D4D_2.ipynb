{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to R and the Jupyter notebook\n",
    "------------------------------------------\n",
    "\n",
    "<img src=\"https://kevinjamesmccauley.files.wordpress.com/2015/02/r-programming-language-logo-785x595.png?w=785\" width=75 style=\"float:left;margin: 0px 15px 15px 0px;\"> We will be using the R language for statistical computing. It has a long history, at least in conception, dating back to the early 1970s. It was developed by statisticians to support \"exploratory data analysis,\" a process we will adapt to help us find stories in data. \n",
    "\n",
    "The practice involves repeated \"looks\" at a data set -- a \"look\" might be some graphical representation of the data like a plot, or the output of some form of computation like a numerical summary, a table, or a \"model\" fit. Statistians are exceptionally visual people, obsessed with \"seeing\" what the data have to offer, and \"views\" maybe provided through a variety of computational means. As a journalist, you might think of this attempt to \"see\" as a kind of interview process, with each subsequent look, a follow-up question. R is, by design, expressive in statistical computations and graphics, meaning it allows us to formulate and act on statistical ideas in an easy way. While we installed R via Anaconda and the Jupyter notebook, most of everyting you need to know about the language, it's uses and extensions, is available on the [R project website](http://r-project.org).\n",
    "\n",
    "<img src=https://github.com/cocteau/D4D/raw/master/images/gettyimages-50530498-612x612.jpg width=400>\n",
    "\n",
    "It's probably worth spending a moment to review the history of R -- Where did it come from? Why was it invented? Who was behind it and what problems were they struggling with. We care about the origin story of our tools because that helps us be on guard for how our analyses are being shaped by the tool makers. Every tool or platform designer has a set of use cases in mind, and you are rewarded for behaving in ways that the designers anticipated. But this can have an affect on the stories that you are capable of finding or telling with data. (Don't get me started on spreadsheets!) Here are a few good resources reviewing where R came from.\n",
    "\n",
    ">[Roger Peng at Johns Hopkins has a Coursera course that starts with an R overview](https://www.coursera.org/learn/r-programming/lecture/pAbaE/overview-and-history-of-r)\n",
    "<br><br>\n",
    "[John Chambers, the designer of a precurser to R called S talks about his motivations](https://web.archive.org/web/20150305201743/http://www.stat.bell-labs.com/S/history.html)\n",
    "<br><br>\n",
    "[The R project website itself has a recounting of its history](https://www.r-project.org/about.html)\n",
    "<br><br>\n",
    "And it's worth seeing who is at the helm of R development these days. [Here's the R-core team from March of 2015](https://web.archive.org/web/20150305213410/https://www.r-project.org/foundation/members.html) and [here is the team today](https://www.r-project.org/foundation/members.html). Notice anyting?\n",
    "\n",
    "The Jupyter notebook you've downloaded provides a very particular *interface* to the R language. (Jupyter actually gives you access to Julia, Python and R -- three languages which explain the name Ju-pyt-er.) You will type commands from the R language into the notebook's \"cells\" and execute them by typing \"shift-enter.\" These code cells are your place to author R, specifying manipulations of and orchestrating looks at your data. \n",
    "\n",
    "Code cells are only half of the story. The notebook also has text cells that allow you to write comments about what you've seen in your data or to even author a final story. The text you enter in these cells will be in  [Markdown](https://daringfireball.net/projects/markdown/), a language that offers a simple way to create HTML pages without writing HTML. It is a \"visual\" language, meaning that you enhance your writing with simple notational conventions that let you read even the unprocessed text easily.  To see Markdown in action, double click on this cell and you'll see the underlying text. Notice that you can make italics by *surrounding text with a pair of asterisks* or boldface by using **pairs of asterisks.** (To return to the HTML view of the Markdown, hold down the shift key and hit \"enter\".)\n",
    "\n",
    "*Now, let's start looking at R. First, you can think of R as a big calculator (a famous statistician R.A. Fisher once said that he learned all he knew over his calculator) and its simplest commands are just arithmetic expressions. Add 2 and 3 below by clicking on the cell and then hit \"enter\" while holding down the shift key -- this sends the R expression \"2+3\" to be evaluated and the answer should be returned.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try these three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5*11\n",
    "20*4+3*sqrt(10)\n",
    "(100+log(25))/300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the cell below to enter 3 more arithmetic expressions and execute them. The top of the cell has a \"comment\" -- in R, any text that starts with a # is ignored and is another way for you to add comments to your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your expressions below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each of these expressions \"returns\" a result, the answer, if you will, to the arithmetic calculation. We can catch the result of a computation in a \"variable\". This lets us use the variable name in place of the object it represents in further calculations. Here we associate the square root of 10 with the variable name \"x\" and we can use it in calculations like multiplying by 10 or adding 100.\n",
    "\n",
    "The symbol `<-` is called the assignment operator. It's a bit of an old-school carry over in that back when S was developed, the APL and AT&T Terminal keyboards each had a single key to express this arrow. Jupyter's R kernel simulates this with a keyboard shortcut that on a Mac is Option-minus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- sqrt(10) \n",
    "x\n",
    "x*9\n",
    "x+100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, data analysis rarely deals in single values. Instead we often deal with \"structured\" data, the most popular structure being that of a simple table. Think an Excel spreadsheet. The data we start with come from the Major Cities Chiefs Association which has been surveying its members to get a sense of where crime is headed. Their report is here -- [MCCA Violent Crime Statistics](https://assets.documentcloud.org/documents/3023302/MCCA-Violent-Crime-Data-Midyear-2016-2015-8716.pdf). When this MCCA data came out in 2016, it was during the election cycle and candidates used them to argue about whether crime was on the rise or not.\n",
    "\n",
    "The data we need is in a PDF table. PDF (the Portable Document Format) is really good for representing data to a printer -- creating a standard like this was a huge deal when PDF was introduced. Often, however, it becomes a vehicle for publishing data and then you start to see its weaknesses. Extracting data from a PDF will depend, first, on the kind of PDF it is. If you can \"select\" text from the document, you're in luck. There are several tools to help you get reasonably close to the data. If, on the other hand, your pages are essentially images, well, then you have to rely on \"optical character recognition\" programs that cluster black and white pixels, say, into letters and words and sentences. \n",
    "\n",
    "I used [Tabula](http://tabula.technology/) to pull the data from the Chiefs' report and convert it to something more usable, a CSV (comma separated values) file. CSV files are a popular format for tabular data. Each line in the file represents a different person or object or \"entity.\" Measurements, or \"attributes\" on a given entity occupy one line in the file and are separated by commas. You can read more about the format [here](https://en.wikipedia.org/wiki/Comma-separated_values). [Download the data](https://github.com/cocteau/D4D/raw/master/data/mcca.csv) and have a look -- perhaps open it in your favorite spreadsheet program.\n",
    "\n",
    "To pull this data into R, we will use a \"function.\" Everything you execute in R, every command, involves executing a function in some way. Through functions, we encapsulate operations that we have to perform repeatedly. In the cell below, we use the function `read.csv()` which does what you might expect -- It reads data in a CSV (comma separated values) file.\n",
    "\n",
    "You can also ask for help about any function in R using, well, another function called `help()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(read.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this help page, you see how you can read in a data set and the different \"arguments\" that might alter the way the data are interpreted or the operation is performed. Below we will call read.csv() using arguments \"sep\" (to change the separator to a tab) and \"as.is\" to do something a bit technical that we'll explain later.\n",
    "\n",
    "Make sure you place the file \"mcca.csv\" into the same folder as you started your notebook from. We'll get into good notebook hygiene, creating folders for separate projects next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs <- read.csv(\"https://github.com/cocteau/D4D/raw/master/data/mcca.csv\")\n",
    "head(chiefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(chiefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `chiefs` is a table and `head()` is a function that shows us the first few lines of the table (by default, the first 6). You can see more or less by adding an argument that specifies how many rows to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from here we see that we can show more lines by adding an argument \"n\". Here's 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(chiefs,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous cell, we used the name `x` to store a numerical value -- the result of a computation. Here, the output from `read_csv()` is R's version of a data table or spreadsheet and it's class is a `data.frame`. Everything in R is an \"object\" meaning it has a \"class\" that you can ask about using the special function `class()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(chiefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to round this out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(2+5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... meaning our simple calculations produced data that is \"numeric\". So we'e seen \"data.frame\" and \"numeric\". Perhaps not surprisingly, help() and read.csv() are functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing. The size of the table. We can use the function dim() to learn a table's dimensions (how many rows and columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(chiefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which means 62 agencies, with 11 different attributes recorded for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mid-year Crime Calculations\n",
    "---------------------------\n",
    "\n",
    "As we mentioned, when the MCCA report appearaed over the summer of 2016, it generated some attention. [CNN](http://www.cnn.com/2016/07/25/politics/violent-crime-report-us-cities-homicides-rapes/), [Breitbart](http://www.breitbart.com/big-government/2016/07/26/survey-violent-crime-major-cities/), [The New York Times](http://www.nytimes.com/2016/05/14/us/murder-rates-cities-fbi.html) and a number of other outlets picked up the data and tried to draw some meaning from it. Have a read and see what you think. \n",
    "\n",
    "In the cell below, write a 3 sentence summary (or less) of what the data are, who collected them and why. With that completed, what kinds of questions do we want to ask about these data? Again, use the cell below to enter a few of them as a bulleted list. You'll need to look at Markdown to see how to do this. Write down 5 questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data:** \n",
    "\n",
    "\n",
    "\n",
    "**My questions**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During his primary run, in a speech the RNC, Trump said that “Our president, who has used the pulpit of the presidency to divide us by race and color, has made America a more dangerous environment for everyone than frankly I have ever seen and anybody in this room has ever watched or seen.” This kicked off a wave of reporting about the safety of our cities. At the DNC in Philadelphia, Obama responded, “Donald Trump calls [America] ‘a divided crime scene’ that only he can fix. It doesn’t matter to him that illegal immigration and the crime rate are as low as they’ve been in decades…”\n",
    "\n",
    "How do we think about these conflicting impressions? The Marshall Project had [a short data piece](https://www.themarshallproject.org/2016/08/18/crime-in-context) about the difference between Trump and Obama's impressions of the crime rate. We'll look at this question while learning a bit of R syntax (heck it's day 1). \n",
    "\n",
    "We are going to make somewhat extensive use of a *package* in R called `dplyr`. This provides us simple tools for manipulating data frames. You can read about the design of the package [here](https://dplyr.tidyverse.org/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing crime rates**. We can compare the overall numbers of homicides in these 62 cities by adding or `sum`ing the columns for 2015 and 2016. Here is the calculation using the `dplyr` function `summarize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(chiefs,tot15=sum(hom15),tot16=sum(hom16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the overall change from 2015 to 2016, we might take the percentage change. That is the difference between homicides in 2016 and 2015 divided by the total in 2015. Here's that calculation by hand. We'll do this the \"R way\" shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(2980-2636)/2636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big increase. Now, let's compute the rates of change for each agency. Rather than work on the crime categories separately, We will focuse on [violent crime](https://ucr.fbi.gov/crime-in-the-u.s/2011/crime-in-the-u.s.-2011/violent-crime/violent-crime). The FBI defines violent crime as the sum of homicides, rapes, robberies and aggravated assault. Let's use R to create these sums.\n",
    "\n",
    "We can use another `dplyr` function called `mutate()` to create a new column in our data set tht represents the sum of the four categories of crime we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutate(chiefs,violent16 = hom16 + rap16 + rob16 + agg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make two new columns to compare violent crime from 2015 and 2016. We'll use `mutate()` again, but with two series of additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs2 <- mutate(chiefs,violent16 = hom16 + rap16 + rob16 + agg16, violent15 = hom15 + rap15 + rob15 + agg15)\n",
    "head(chiefs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the change for each city. This is defined as the difference between 2016 and 2016 as a fraction of 2015's total. In this case, we'll just add a column called `change` to the data frame, referring back to the new `violent15` and `violent16` we created. But we'll do it in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs2 <- mutate(chiefs,violent16 = hom16 + rap16 + rob16 + agg16, violent15 = hom15 + rap15 + rob15 + agg15, change=(violent16-violent15)/violent15)\n",
    "head(chiefs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we work with R, we create objects along the way. For example, we read in `chiefs` from our GitHub account and then we created `chiefs2` that had three new columns added. We can see the objects we've made by using the command `objects()`. If we want, we can `rm()` remove things we don't need. (R is a 'main memory' program, meaning you can only have objects as big as your computer's memory. It's unlikely you'll hit that limit, but it never hurts to be tidy.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(x)\n",
    "objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to the crime rate.** We might reasonably ask about which cities are on the rise and which have had falling crime numbers. We can use a \"logical expression\" for this. It will return a set of boolean data types, `TRUE` and `FALSE`. (Notice that we don't have to keep making new data frames -- `chiefs2`, `chiefs3` and so on -- we can just *overwrite* the original data set if are just adding columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs3 <- mutate(chiefs2,increase=change>0)\n",
    "head(chiefs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can look at how many departments experienced an increase versus a decrease..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(chiefs3,increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is an `NA` or missing value. We might want to identify that PD and then drop it so that it doesn't interfere with our calculations. We can use the `dplyr` verb `filter()` to subset rows of a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(chiefs3,is.na(increase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can flip a `TRUE` to a `FALSE` using the `!` (bang) exclamation mark. The expression below overwrites `chiefs3` by keeping just those rows that are not missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs3 <- filter(chiefs3,!is.na(increase))\n",
    "count(chiefs3,increase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filter()` can be handy to isolate cases we are interested in, and not just because the data are missing. We could focus on certain states (if our data had that) or other characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(chiefs3,change>0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(chiefs3,change< -0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's have a look. We will use a *histogram* to show the data. This is another frequency display like the barplot we saw yesterday. In this case, the range of the data is (typically) divided into equally-sized intervals or \"bins\" and we then count the number of data points falling in each interval. The count is given by the height of a bar over the interval. \n",
    "\n",
    "We are going to use another package that, in this case, makes working with plots much easier. It is written by the same chap who authored the `dplyr` package -- he's been quite busy tidying up around the edges of R. The library we need is called `ggplot2` which stands for the grammar of graphics... uh, 2.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command below just has you setting the width and height of the plot. It's obscure, but you just copy it from cell to cell when you need to change the shape of your graphic. The second commnd makes a plot and then adds to it a histogram primitive. We will talk a lot more about the grammr of graphics, but for now, we can make a simple histogram to see what our changes \"looked like.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=10,repr.plot.height=6)\n",
    "\n",
    "ggplot(chiefs3) + geom_histogram(aes(x=change),bins=10,color=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this distirbution of changes in violent cirme, I notice ....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see? Change the breaks and tell me what you see. Now, let's use that logical mask again, this time to find our errant row with missing data and to create a data frame that leaves it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "National trends\n",
    "---------------\n",
    "\n",
    "The data we've been looking captures just the last year -- well six months of 2015 and six months of 2016. It is a bit dangerous to make interpretations based on just one year's data. Crime fluctuates naturally from year to year and those fluctuations are best understood in terms of larger overall trends. To assess these trends, we appeal to the Uniform Crime Reports compiled by the FBI. You can [access the raw data here.](https://www.icpsr.umich.edu/icpsrweb/NACJD/series/57) I have a nicer form of the data for you already [loaded on our GitHub account](https://github.com/cocteau/D4D/raw/master/data/ucr_crime_1975_2015.csv). Download it and put it in the same folder as this notebook (or we can read it directly from GitHub).\n",
    "\n",
    "Let's bring it into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucr <- read.csv(\"https://github.com/cocteau/D4D/raw/master/data/ucr_crime_1975_2015.csv\",as.is=TRUE)\n",
    "head(ucr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail(ucr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(ucr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how many cities we have per year, we are going to use the `dplyr` command `group_by()` to group the data by year and then call `summarize()` to count the number of entries (cities) per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(group_by(ucr,year),count=n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we are doing the same by department, to see how many years worth of data we have for each department. It's very regular!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(group_by(ucr,department_name),count=n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(ucr,is.na(violent_crime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure we understand the columns, violent crime is meant to be a combination of homicides, rapes, robberies and aggravated assault. Let's form that sum and compare it to the violent crime column in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucr <- mutate(ucr,test = homs_sum+rape_sum+rob_sum+agg_ass_sum)\n",
    "head(ucr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(ucr,check = sum(test==violent_crime,na.rm=TRUE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be cleaer, let's look at places that have huge crime numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter(ucr,violent_crime > 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... ah, there are national totals in this data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter(ucr,violent_crime > 100000 & department_name != \"National\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's have a look at one municipality. Let's pull the data aside and make some plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miami <- filter(ucr, department_name==\"Miami\")\n",
    "miami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=8,repr.plot.height=4)\n",
    "\n",
    "ggplot(miami,aes(x=year,y=violent_per_100k)) + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(miami,aes(x=year,y=violent_per_100k)) + \n",
    "    geom_point()+\n",
    "    xlab(\"Year\")+\n",
    "    ylab(\"Violent Crimes per 100K People\")+\n",
    "    ggtitle(\"Crime Rate in Miami\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot for a city larger than Miami and a plot for a city smaller than Miami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to pick your city\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to plot the big city\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to plot the smaller city\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trends** How do we separate a smooth trend from the yearly fluctuations that are typical for crime statistics? In your introductory class, you probably learned about regression. What kind of model was that and what was it trying to do with the data? Here's how R might fit a line. What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(miami,aes(x=year,y=violent_per_100k)) + \n",
    "    geom_point()+\n",
    "    geom_smooth(method=\"lm\",se=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local regression (or loess) is like fitting a line but it does it, well, locally. Think about fitting a number of lines along the years. This will give us a \"smooth curve\" that we can play with, allowing us to make different contrasts between trend and fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(miami,aes(x=year,y=violent_per_100k)) + \n",
    "    geom_point()+\n",
    "    geom_smooth(method=\"loess\",se=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(miami,aes(x=year,y=violent_per_100k)) + \n",
    "    geom_point()+\n",
    "    geom_smooth(method=\"loess\",se=FALSE,span=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we overlay the smooth on the actual data. The \"span\" parameter controls the amount of smoothing by only using span percentage of the data in each fit. If span is small, the curve will be wiggly and if it is large, it will be smoother. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(ucr,aes(x=year,y=violent_per_100k,group=department_name)) + \n",
    "    geom_smooth(method=\"loess\",se=FALSE,color=\"black\",lwd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplot(ucr,aes(x=year,y=violent_per_100k,group=department_name)) + geom_line(lwd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This little introduction was part of a story by Tom Meagher and Gabe Dance at The Marshall Project. Have a look at thier [Crime in Context](https://www.themarshallproject.org/2016/08/18/crime-in-context) to see where these tools proved helpful. You will look at clustering in your homework assignment.\n",
    "\n",
    "**Short assignment for today.** See if you can get the data into shape from the Major Cities Chiefs Association for 2016-2017, and update your analysis. The original report that generated the CSV we used [is posted here](https://www.majorcitieschiefs.com/pdf/news/mcca_violent_crime_data_midyear_20162015.pdf). The updated version for 2016-2017 [is posted here](https://www.majorcitieschiefs.com/pdf/news/mcca_violent_crime_report_2017_and_2016_midyear_07312017_update.pdf). Grab the file and see what you can do with it. Remember, I used [Tabula](http://tabula.technology/) to pull the data from the Chiefs' report and convert it to the more usable CSV file we loaded into R. See what you can do to convert the new file and try loading it into R.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
